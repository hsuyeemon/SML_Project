{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VUuB5ETlvfPV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/hsuyeemon/SML_Project/main/data/life%20expectancy.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL2fle0sbzMz"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows after dropping :  3118\n"
          ]
        }
      ],
      "source": [
        "# we will use only the rows where the target Life Expectancy value present.\n",
        "df = df[~df['Life Expectancy World Bank'].isna()]\n",
        "print(\"Number of rows after dropping : \", df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO : // get a subset of data for project  \n",
        "# We will use the data from \"East Asia & Pacific,South Asia and Europe & Central Asia\" region since 2010.\n",
        "# data = data[data['Year']>=2010]\n",
        "# data = data[(data['Region'] == 'East Asia & Pacific') | (data['Region'] == 'South Asia')| (data['Region'] == 'Europe & Central Asia')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "fa-ssIwwxz82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data points after filtered 2375\n",
            "The missing value percent\n",
            " Health Expenditure %        0.084211\n",
            "Education Expenditure %    17.347368\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# handle missing data\n",
        "# remove the countries has over 50% of missing data in Health or Education column\n",
        "values_to_drop  = [ \n",
        "    'Algeria','Antigua and Barbuda','Bermuda','Bolivia',\n",
        "    'Botswana','Canada','Comoros','Eritrea','France',\n",
        "    'Greece','Greenland','Grenada','Haiti','Honduras',\n",
        "    'Iraq','Liberia','Luxembourg','Morocco','Nicaragua',\n",
        "    'North Macedonia','Papua New Guinea','Puerto Rico','South Sudan',\n",
        "    'Sudan','Suriname','Tonga','Turkmenistan','United Arab Emirates','United States',\n",
        "    'Uzbekistan','Vanuatu','Zimbabwe','Dominica','Montenegro',\n",
        "    'Palau','Bosnia and Herzegovina','Equatorial Guinea','Guam','Nigeria','Somalia',\n",
        "    'Bosnia and Herzegovina','Equatorial Guinea','Guam','Libya','Nigeria','Somalia',\n",
        "]\n",
        "\n",
        "df_filtered = df[~df['Country Name'].isin(values_to_drop)]\n",
        "print(\"data points after filtered\" , df_filtered.shape[0])\n",
        "percentage_missing = (df_filtered[['Health Expenditure %','Education Expenditure %']].isnull().sum() / len(df_filtered)) * 100\n",
        "print(\"The missing value percent\\n\",percentage_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hsuye\\AppData\\Local\\Temp\\ipykernel_15892\\197104411.py:120: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_subset['Health Expenditure %'] = df_subset.groupby('Country Name')['Health Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n",
            "C:\\Users\\hsuye\\AppData\\Local\\Temp\\ipykernel_15892\\197104411.py:124: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_subset['Education Expenditure %'] = df_subset.groupby('Country Name')['Education Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n"
          ]
        }
      ],
      "source": [
        "# Define the subset of countries we want to impute\n",
        "countries_to_impute = [\n",
        "    'Afghanistan',\n",
        "'Albania',\n",
        "'Angola',\n",
        "'Australia',\n",
        "'Austria',\n",
        "'Bahrain',\n",
        "'Bangladesh',\n",
        "'Barbados',\n",
        "'Belarus',\n",
        "'Belgium',\n",
        "'Belize',\n",
        "'Bhutan',\n",
        "'Brazil',\n",
        "'Bulgaria',\n",
        "'Burkina Faso',\n",
        "'Burundi',\n",
        "'Cambodia',\n",
        "'Cameroon',\n",
        "'Central African Republic',\n",
        "'Chad',\n",
        "'Chile',\n",
        "'China',\n",
        "'Costa Rica',\n",
        "'Croatia',\n",
        "'Cuba',\n",
        "'Cyprus',\n",
        "'Denmark',\n",
        "'Djibouti',\n",
        "'Dominican Republic',\n",
        "'Ecuador',\n",
        "'El Salvador',\n",
        "'Estonia',\n",
        "'Eswatini',\n",
        "'Ethiopia',\n",
        "'Fiji',\n",
        "'Finland',\n",
        "'Gabon',\n",
        "'Germany',\n",
        "'Ghana',\n",
        "'Guatemala',\n",
        "'Guinea',\n",
        "'Guinea-Bissau',\n",
        "'Guyana',\n",
        "'Hungary',\n",
        "'Iceland',\n",
        "'India',\n",
        "'Indonesia',\n",
        "'Ireland',\n",
        "'Israel',\n",
        "'Italy',\n",
        "'Jamaica',\n",
        "'Japan',\n",
        "'Jordan',\n",
        "'Kazakhstan',\n",
        "'Kenya',\n",
        "'Kiribati',\n",
        "'Kuwait',\n",
        "'Latvia',\n",
        "'Lebanon',\n",
        "'Lesotho',\n",
        "'Lithuania',\n",
        "'Malawi',\n",
        "'Malaysia',\n",
        "'Maldives',\n",
        "'Mali',\n",
        "'Malta',\n",
        "'Mauritania',\n",
        "'Mexico',\n",
        "'Mongolia',\n",
        "'Mozambique',\n",
        "'Myanmar',\n",
        "'Namibia',\n",
        "'Netherlands',\n",
        "'New Zealand',\n",
        "'Niger',\n",
        "'Norway',\n",
        "'Oman',\n",
        "'Pakistan',\n",
        "'Panama',\n",
        "'Paraguay',\n",
        "'Philippines',\n",
        "'Poland',\n",
        "'Portugal',\n",
        "'Qatar',\n",
        "'Romania',\n",
        "'Rwanda',\n",
        "'Samoa',\n",
        "'Sao Tome and Principe',\n",
        "'Saudi Arabia',\n",
        "'Senegal',\n",
        "'Serbia',\n",
        "'Seychelles',\n",
        "'Sierra Leone',\n",
        "'Slovenia',\n",
        "'Solomon Islands',\n",
        "'Spain',\n",
        "'Sri Lanka',\n",
        "'Sweden',\n",
        "'Switzerland',\n",
        "'Tajikistan',\n",
        "'Tanzania',\n",
        "'Trinidad and Tobago',\n",
        "'Tunisia',\n",
        "'Uganda',\n",
        "'United Kingdom',\n",
        "'Uruguay',\n",
        "'Vietnam',\n",
        "'Zambia',\n",
        "'Iraq',\n",
        "'Zimbabwe',\n",
        "]\n",
        "\n",
        "\n",
        "# Filter the DataFrame to include only the specified countries\n",
        "df_subset = df_filtered[df_filtered['Country Name'].isin(countries_to_impute)]\n",
        "\n",
        "# Calculate mean for each country group and impute missing values\n",
        "df_subset['Health Expenditure %'] = df_subset.groupby('Country Name')['Health Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "# Calculate mean for each country group and impute missing values\n",
        "#print(df_subset.groupby('Country Name')['Education Expenditure %'].transform(lambda x: x.fillna(x.mean())))\n",
        "df_subset['Education Expenditure %'] = df_subset.groupby('Country Name')['Education Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "# Merge the subset back into the original DataFrame\n",
        "df_imputed = pd.concat([df_filtered[~df_filtered['Country Name'].isin(countries_to_impute)], df_subset])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The size of data is 2375\n",
            "The missing value percent\n",
            " Health Expenditure %          0.0\n",
            "Education Expenditure %       0.0\n",
            "Life Expectancy World Bank    0.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# get the columns of interest\n",
        "df_cleaned = df_imputed[['Health Expenditure %','Education Expenditure %','Life Expectancy World Bank']]\n",
        "print(\"The size of data is\",df_cleaned.shape[0])\n",
        "percentage_missing = (df_cleaned.isnull().sum() / len(df_cleaned)) * 100\n",
        "print(\"The missing value percent\\n\",percentage_missing) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove outliers\n",
        "df_cleaned = df_cleaned[(df_cleaned['Education Expenditure %'] <=8) & (df_cleaned['Health Expenditure %'] <= 12)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ISRAD4PTyg2U"
      },
      "outputs": [],
      "source": [
        "X = df_cleaned[['Health Expenditure %','Education Expenditure %']] #input\n",
        "y = df_cleaned['Life Expectancy World Bank'] #output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnD1HgnAtQGS"
      },
      "source": [
        "Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "AxRVwNuC3Bfx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.4, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIzF6GNxtSnE"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "4QbE5R4XdwS3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "steps = [ (\"scale\", StandardScaler()),  #standardizing the data to range ( mean = 0 ,variance = 1)\n",
        "          (\"polytransform\", PolynomialFeatures(degree = 2)), # transforming the polinomial to linear\n",
        "          (\"regressor\", Ridge(1)) ] # Ridge Model\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "model = pipeline.fit(X_train, y_train)  # goal :  to find the parameters , minimize the error between the error and actual data , doing optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArkB47AFtVbD"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDCT-Un82kLR",
        "outputId": "2dc62cd5-62dd-45d4-a087-d7b703a9dfb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n",
            "mae: 7 mse: 71 r2 score: 0.2\n",
            "testing\n",
            "mae: 6 mse: 69 r2 score: 0.22\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Evaluating on the training data\n",
        "y_pred = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "r2 = r2_score(y_train,y_pred)\n",
        "print('training')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n",
        "\n",
        "\n",
        "# Evaluating on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print('testing')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_deploy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

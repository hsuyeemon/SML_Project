{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VUuB5ETlvfPV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/hsuyeemon/SML_Project/main/data/life%20expectancy.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL2fle0sbzMz"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows after dropping :  3118\n"
          ]
        }
      ],
      "source": [
        "# we will use only the rows where the target Life Expectancy value present.\n",
        "df = df[~df['Life Expectancy World Bank'].isna()]\n",
        "print(\"Number of rows after dropping : \", df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO : // get a subset of data for project  \n",
        "\n",
        "# Reference\n",
        "# We will use the data from \"East Asia & Pacific,South Asia and Europe & Central Asia\" region since 2010.\n",
        "#df = df[df['Year']>=2010]\n",
        "\n",
        "# regions_filter = ['','']\n",
        "# df = df[df['Region'].isin(regions_filter)]\n",
        "# data = data[(data['Region'] == 'East Asia & Pacific') | (data['Region'] == 'South Asia')| (data['Region'] == 'Europe & Central Asia')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hc_drop = []\n",
        "hc_impute = []\n",
        "\n",
        "ec_drop = []\n",
        "ec_impute = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examining Health Data\n",
        "\n",
        "# Group by 'Country' and count the number of unique years\n",
        "country_year_counts = df[['Country Name','Year','Health Expenditure %']].groupby('Country Name')['Year'].nunique() \n",
        "# Filter out countries with less than 5 years of data\n",
        "countries_with_less_than_5_years = country_year_counts[country_year_counts < 5].index.tolist()\n",
        "\n",
        "# Filter out countries to impute\n",
        "countries_with_less_than_19_years = country_year_counts[country_year_counts < 19 and country_year_counts>=5].index.tolist()\n",
        "\n",
        "# Get a list of unique countries\n",
        "all_countries = df['Country Name'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Dominica', 'Palau']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "countries_with_less_than_20_years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Dominica', 'Palau']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hc_drop.append(countries_with_less_than_5_years)\n",
        "hc_impute.append(countries_with_less_than_19_years)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fa-ssIwwxz82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data points after filtered 1250\n",
            "The missing value percent\n",
            " Health Expenditure %        0.08\n",
            "Education Expenditure %    10.64\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# handle missing data\n",
        "\n",
        "values_to_drop  = [ \n",
        "    'Algeria','Antigua and Barbuda','Bermuda','Bolivia',\n",
        "    'Botswana','Canada','Comoros','Eritrea','France',\n",
        "    'Greece','Greenland','Grenada','Haiti','Honduras',\n",
        "    'Iraq','Liberia','Luxembourg','Morocco','Nicaragua',\n",
        "    'North Macedonia','Papua New Guinea','Puerto Rico','South Sudan',\n",
        "    'Sudan','Suriname','Tonga','Turkmenistan','United Arab Emirates','United States',\n",
        "    'Uzbekistan','Vanuatu','Zimbabwe','Dominica','Montenegro',\n",
        "    'Palau','Bosnia and Herzegovina','Equatorial Guinea','Guam','Libya','Nigeria',\n",
        "    'Somalia',\n",
        "]\n",
        "\n",
        "df_filtered = df[~df['Country Name'].isin(values_to_drop)]\n",
        "print(\"data points after filtered\" , df_filtered.shape[0])\n",
        "percentage_missing = (df_filtered[['Health Expenditure %','Education Expenditure %']].isnull().sum() / len(df_filtered)) * 100\n",
        "print(\"The missing value percent\\n\",percentage_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hsuye\\AppData\\Local\\Temp\\ipykernel_18440\\2536136589.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_subset['Education Expenditure %'] = df_subset.groupby('Country Name')['Education Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n",
            "C:\\Users\\hsuye\\AppData\\Local\\Temp\\ipykernel_18440\\2536136589.py:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_subset['Health Expenditure %'] = df_subset.groupby('Country Name')['Health Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n"
          ]
        }
      ],
      "source": [
        "# Define the subset of countries we want to impute\n",
        "countries_to_impute = [\n",
        "    'Afghanistan','Albania','Angola','Australia','Austria','Bahrain',\n",
        "    'Bangladesh','Barbados','Belarus','Belgium','Belize','Bhutan','Brazil',\n",
        "    'Bulgaria','Burkina Faso','Burundi','Cambodia','Cameroon','Central African Republic',\n",
        "    'Chad','Chile','China','Costa Rica','Croatia','Cuba','Cyprus',\n",
        "    'Denmark','Djibouti','Dominican Republic','Ecuador','El Salvador',\n",
        "    'Estonia','Eswatini','Ethiopia','Fiji','Finland','Gabon','Germany',\n",
        "    'Ghana','Guatemala','Guinea','Guinea-Bissau','Guyana','Hungary',\n",
        "    'Iceland','India','Indonesia','Ireland','Israel','Italy',\n",
        "    'Jamaica','Japan','Jordan','Kazakhstan','Kenya','Kiribati',\n",
        "    'Kuwait','Latvia','Lebanon','Lesotho','Lithuania',\n",
        "    'Malawi','Malaysia','Maldives','Mali','Malta','Mauritania',\n",
        "    'Mexico','Mongolia','Mozambique','Myanmar','Namibia',\n",
        "    'Netherlands','New Zealand','Niger','Norway','Oman',\n",
        "    'Pakistan','Panama','Paraguay','Philippines','Poland',\n",
        "    'Portugal','Qatar','Romania','Rwanda','Samoa','Sao Tome and Principe',\n",
        "    'Saudi Arabia','Senegal','Serbia','Seychelles','Sierra Leone',\n",
        "    'Slovenia','Solomon Islands','Spain','Sri Lanka','Sweden',\n",
        "    'Switzerland','Tajikistan','Tanzania','Trinidad and Tobago',\n",
        "    'Tunisia','Uganda','United Kingdom','Uruguay','Vietnam','Zambia',\n",
        "]\n",
        "\n",
        "\n",
        "# Filter the DataFrame to include only the specified countries\n",
        "df_subset = df_filtered[df_filtered['Country Name'].isin(countries_to_impute)]\n",
        "\n",
        "\n",
        "# Calculate mean for each country group and impute missing values\n",
        "#print(df_subset.groupby('Country Name')['Education Expenditure %'].transform(lambda x: x.fillna(x.mean())))\n",
        "df_subset['Education Expenditure %'] = df_subset.groupby('Country Name')['Education Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "# Merge the subset back into the original DataFrame\n",
        "df_imputed = pd.concat([df_filtered[~df_filtered['Country Name'].isin(countries_to_impute)], df_subset])\n",
        "\n",
        "\n",
        "heath_imp = ['Afghanistan',\n",
        "'Albania',\n",
        "'Iraq',\n",
        "'Zimbabwe',\n",
        "]\n",
        "\n",
        "# Filter the DataFrame to include only the specified countries\n",
        "df_subset = df_imputed [df_imputed['Country Name'].isin(heath_imp)]\n",
        "\n",
        "\n",
        "# Calculate mean for each country group and impute missing values\n",
        "df_subset['Health Expenditure %'] = df_subset.groupby('Country Name')['Health Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "\n",
        "# Merge the subset back into the original DataFrame\n",
        "df_imputed = pd.concat([df_imputed[~df_imputed['Country Name'].isin(heath_imp)], df_subset])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The size of data is 1250\n",
            "The missing value percent\n",
            " Health Expenditure %          0.0\n",
            "Education Expenditure %       0.0\n",
            "Life Expectancy World Bank    0.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# get the columns of interest\n",
        "df_cleaned = df_imputed[['Health Expenditure %','Education Expenditure %','Life Expectancy World Bank']]\n",
        "print(\"The size of data is\",df_cleaned.shape[0])\n",
        "percentage_missing = (df_cleaned.isnull().sum() / len(df_cleaned)) * 100\n",
        "print(\"The missing value percent\\n\",percentage_missing) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove outliers\n",
        "df_cleaned = df_cleaned[(df_cleaned['Education Expenditure %'] <=8) & (df_cleaned['Health Expenditure %'] <= 12)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ISRAD4PTyg2U"
      },
      "outputs": [],
      "source": [
        "X = df_cleaned[['Health Expenditure %','Education Expenditure %']] #input\n",
        "y = df_cleaned['Life Expectancy World Bank'] #output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnD1HgnAtQGS"
      },
      "source": [
        "Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AxRVwNuC3Bfx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIzF6GNxtSnE"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4QbE5R4XdwS3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "steps = [ (\"scale\", StandardScaler()),  #standardizing the data to range ( mean = 0 ,variance = 1)\n",
        "          (\"polytransform\", PolynomialFeatures(degree = 3)), # transforming the polinomial to linear\n",
        "          (\"regressor\", Ridge(1)) ] # Ridge Model\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "model = pipeline.fit(X_train, y_train)  # goal :  to find the parameters , minimize the error between the error and actual data , doing optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArkB47AFtVbD"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDCT-Un82kLR",
        "outputId": "2dc62cd5-62dd-45d4-a087-d7b703a9dfb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n",
            "mae: 5 mse: 50 r2 score: 0.26\n",
            "testing\n",
            "mae: 6 mse: 60 r2 score: 0.2\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Evaluating on the training data\n",
        "y_pred = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "r2 = r2_score(y_train,y_pred)\n",
        "print('training')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n",
        "\n",
        "\n",
        "# Evaluating on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print('testing')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_deploy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VUuB5ETlvfPV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/hsuyeemon/SML_Project/main/data/life%20expectancy.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL2fle0sbzMz"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows after dropping :  3118\n"
          ]
        }
      ],
      "source": [
        "# we will use only the rows where the target Life Expectancy value present.\n",
        "df = df[~df['Life Expectancy World Bank'].isna()]\n",
        "print(\"Number of rows after dropping : \", df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The missing value percent\n",
            " Health Expenditure %        4.554201\n",
            "Education Expenditure %    31.205901\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "percentage_missing = (df[['Health Expenditure %','Education Expenditure %']].isnull().sum() / len(df)) * 100\n",
        "print(\"The missing value percent\\n\",percentage_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO : // get a subset of data for project  \n",
        "\n",
        "# Reference\n",
        "# We will use the data from \"East Asia & Pacific,South Asia and Europe & Central Asia\" region since 2010.\n",
        "#df = df[df['Year']>=2010]\n",
        "\n",
        "# regions_filter = ['','']\n",
        "# df = df[df['Region'].isin(regions_filter)]\n",
        "# data = data[(data['Region'] == 'East Asia & Pacific') | (data['Region'] == 'South Asia')| (data['Region'] == 'Europe & Central Asia')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtered = df[~df['Country Name'].isin(['Dominica', 'Palau'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_filtered=df_filtered[(df_filtered['Region'] == 'East Asia & Pacific') | (df_filtered['Region'] == 'South Asia')| (df_filtered['Region'] == 'Europe & Central Asia')]\n",
        "df_filtered=df_filtered[(df_filtered['Region'] == 'East Asia & Pacific')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The missing value percent\n",
            " Health Expenditure %    4.761905\n",
            "Health Expenditure %    4.761905\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "percentage_missing = (df_filtered[['Health Expenditure %','Health Expenditure %']].isnull().sum() / len(df_filtered)) * 100\n",
        "print(\"The missing value percent\\n\",percentage_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Guam', 'Papua New Guinea', 'Tonga']\n",
            "['Australia', 'China', 'Guam', 'Myanmar', 'Mongolia', 'Papua New Guinea', 'Solomon Islands', 'Vietnam', 'Kiribati', 'Fiji', 'Cambodia', 'Samoa', 'Vanuatu', 'Malaysia', 'Tonga', 'Indonesia', 'Japan', 'Philippines', 'New Zealand']\n"
          ]
        }
      ],
      "source": [
        "# Group by 'Country' and count the number of unique years\n",
        "country_edu_data_counts = df_filtered[['Country Name','Education Expenditure %']].groupby('Country Name')['Education Expenditure %'].nunique() \n",
        "\n",
        "# Filter out countries with less than 5 years of data\n",
        "countries_edu_with_less_than_5_years = country_edu_data_counts[country_edu_data_counts <8].index.tolist()\n",
        "\n",
        "# Filter out countries to impute\n",
        "countries_edu_with_null_value = df_filtered[df_filtered['Education Expenditure %'].isna() == True]['Country Name'].unique().tolist()\n",
        "\n",
        "print(countries_edu_with_less_than_5_years)\n",
        "print(countries_edu_with_null_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Guam']\n",
            "['Guam']\n"
          ]
        }
      ],
      "source": [
        "# Group by 'Country' and count the number of unique years\n",
        "country_hea_data_counts = df_filtered[['Country Name','Health Expenditure %']].groupby('Country Name')['Health Expenditure %'].nunique() \n",
        "\n",
        "# Filter out countries with less than 5 years of data\n",
        "countries_hea_with_less_than_5_years = country_hea_data_counts[country_hea_data_counts < 8].index.tolist()\n",
        "\n",
        "# Filter out countries to impute\n",
        "countries_hea_with_null_value = df_filtered[df_filtered['Health Expenditure %'].isna() == True]['Country Name'].unique().tolist()\n",
        "\n",
        "\n",
        "print(countries_hea_with_less_than_5_years)\n",
        "print(countries_hea_with_null_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data points after filtered 342\n",
            "data points after filtered 342\n"
          ]
        }
      ],
      "source": [
        "# handle missing data\n",
        "\n",
        "df_filtered = df_filtered[~df_filtered['Country Name'].isin(countries_edu_with_less_than_5_years)]\n",
        "print(\"data points after filtered\" , df_filtered.shape[0])\n",
        "\n",
        "df_filtered = df_filtered[~df_filtered['Country Name'].isin(countries_hea_with_less_than_5_years)]\n",
        "print(\"data points after filtered\" , df_filtered.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fa-ssIwwxz82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The missing value percent\n",
            " Education Expenditure %    0.0\n",
            "dtype: float64\n",
            "The missing value percent\n",
            " Health Expenditure %    0.0\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hsuye\\AppData\\Local\\Temp\\ipykernel_9208\\2811823287.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_subset['Education Expenditure %'] = df_subset.groupby('Country Name')['Education Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n"
          ]
        }
      ],
      "source": [
        "# imputation\n",
        "\n",
        "# Filter the DataFrame to include only the specified countries\n",
        "df_subset = df_filtered[df_filtered['Country Name'].isin(countries_edu_with_null_value)]\n",
        "\n",
        "# Calculate mean for each country group and impute missing values\n",
        "#print(df_subset.groupby('Country Name')['Education Expenditure %'].transform(lambda x: x.fillna(x.mean())))\n",
        "df_subset['Education Expenditure %'] = df_subset.groupby('Country Name')['Education Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "# Merge the subset back into the original DataFrame\n",
        "df_imputed = pd.concat([df_filtered[~df_filtered['Country Name'].isin(countries_edu_with_null_value)], df_subset])\n",
        "\n",
        "percentage_missing = (df_imputed[['Education Expenditure %']].isnull().sum() / len(df_imputed)) * 100\n",
        "print(\"The missing value percent\\n\",percentage_missing)\n",
        "\n",
        "\n",
        "\n",
        "# Filter the DataFrame to include only the specified countries\n",
        "df_subset = df_imputed[df_imputed['Country Name'].isin(countries_hea_with_null_value)]\n",
        "\n",
        "# Calculate mean for each country group and impute missing values\n",
        "#print(df_subset.groupby('Country Name')['Education Expenditure %'].transform(lambda x: x.fillna(x.mean())))\n",
        "df_subset['Health Expenditure %'] = df_subset.groupby('Country Name')['Health Expenditure %'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "# Merge the subset back into the original DataFrame\n",
        "df_imputed = pd.concat([df_imputed[~df_imputed['Country Name'].isin(countries_hea_with_null_value)], df_subset])\n",
        "\n",
        "percentage_missing = (df_imputed[['Health Expenditure %']].isnull().sum() / len(df_imputed)) * 100\n",
        "print(\"The missing value percent\\n\",percentage_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The size of data is 342\n",
            "The missing value percent\n",
            " Health Expenditure %          0.0\n",
            "Education Expenditure %       0.0\n",
            "Life Expectancy World Bank    0.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# get the columns of interest\n",
        "df_cleaned = df_imputed[['Health Expenditure %','Education Expenditure %','Life Expectancy World Bank']]\n",
        "print(\"The size of data is\",df_cleaned.shape[0])\n",
        "percentage_missing = (df_cleaned.isnull().sum() / len(df_cleaned)) * 100\n",
        "print(\"The missing value percent\\n\",percentage_missing) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove outliers\n",
        "df_cleaned = df_cleaned[(df_cleaned['Education Expenditure %'] <=8) & (df_cleaned['Health Expenditure %'] <= 12)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ISRAD4PTyg2U"
      },
      "outputs": [],
      "source": [
        "X = df_cleaned[['Health Expenditure %','Education Expenditure %']] #input\n",
        "y = df_cleaned['Life Expectancy World Bank'] #output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnD1HgnAtQGS"
      },
      "source": [
        "Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "AxRVwNuC3Bfx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.28, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIzF6GNxtSnE"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArkB47AFtVbD"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDCT-Un82kLR",
        "outputId": "2dc62cd5-62dd-45d4-a087-d7b703a9dfb7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge , LinearRegression , Lasso\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression\n",
            "training\n",
            "mae: 4 mse: 23 r2 score: 0.39\n",
            "testing\n",
            "mae: 4 mse: 25 r2 score: 0.29\n"
          ]
        }
      ],
      "source": [
        "print(\"Linear Regression\")\n",
        "steps = [ (\"scale\", StandardScaler()),  #standardizing the data to range ( mean = 0 ,variance = 1)\n",
        "          (\"regressor\", LinearRegression()) ] # Ridge Model\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "model = pipeline.fit(X_train, y_train)  # goal :  to find the parameters , minimize the error between the error and actual data , doing optimization\n",
        "\n",
        "# Evaluating on the training data\n",
        "y_pred = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "r2 = r2_score(y_train,y_pred)\n",
        "print('training')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n",
        "\n",
        "\n",
        "# Evaluating on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print('testing')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "degree =5\n",
        "alpha = 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Poly Regression\n",
            "training\n",
            "mae: 3 mse: 11 r2 score: 0.71\n",
            "testing\n",
            "mae: 2 mse: 11 r2 score: 0.7\n"
          ]
        }
      ],
      "source": [
        "print(\"Poly Regression\")\n",
        "\n",
        "steps = [ (\"scale\", StandardScaler()),  #standardizing the data to range ( mean = 0 ,variance = 1)\n",
        "          (\"polytransform\", PolynomialFeatures(degree = degree)), # transforming the polinomial to linear\n",
        "          (\"regressor\", LinearRegression()) ] # Ridge Model\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "model = pipeline.fit(X_train, y_train)  # goal :  to find the parameters , minimize the error between the error and actual data , doing optimization\n",
        "\n",
        "# Evaluating on the training data\n",
        "y_pred = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "r2 = r2_score(y_train,y_pred)\n",
        "print('training')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n",
        "\n",
        "\n",
        "# Evaluating on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print('testing')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Poly-Ridge Regression\n",
            "training\n",
            "mae: 3 mse: 11 r2 score: 0.71\n",
            "testing\n",
            "mae: 2 mse: 11 r2 score: 0.69\n"
          ]
        }
      ],
      "source": [
        "print(\"Poly-Ridge Regression\")\n",
        "\n",
        "steps = [ (\"scale\", StandardScaler()),  #standardizing the data to range ( mean = 0 ,variance = 1)\n",
        "          (\"polytransform\", PolynomialFeatures(degree = degree)), # transforming the polinomial to linear\n",
        "          (\"regressor\", Ridge(alpha)) ] # Ridge Model\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "model = pipeline.fit(X_train, y_train)  # goal :  to find the parameters , minimize the error between the error and actual data , doing optimization\n",
        "\n",
        "# Evaluating on the training data\n",
        "y_pred = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "r2 = r2_score(y_train,y_pred)\n",
        "print('training')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n",
        "\n",
        "\n",
        "# Evaluating on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print('testing')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Poly-Lasso Regression\n",
            "training\n",
            "mae: 3 mse: 17 r2 score: 0.56\n",
            "testing\n",
            "mae: 4 mse: 18 r2 score: 0.47\n"
          ]
        }
      ],
      "source": [
        "print(\"Poly-Lasso Regression\")\n",
        "\n",
        "steps = [ (\"scale\", StandardScaler()),  #standardizing the data to range ( mean = 0 ,variance = 1)\n",
        "          (\"polytransform\", PolynomialFeatures(degree = degree)), # transforming the polinomial to linear\n",
        "          (\"regressor\", Lasso(alpha)) ] # Ridge Model\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "model = pipeline.fit(X_train, y_train)  # goal :  to find the parameters , minimize the error between the error and actual data , doing optimization\n",
        "\n",
        "# Evaluating on the training data\n",
        "y_pred = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "r2 = r2_score(y_train,y_pred)\n",
        "print('training')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n",
        "\n",
        "\n",
        "# Evaluating on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print('testing')\n",
        "print('mae:', round(mae), 'mse:', round(mse), 'r2 score:', round(r2, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_deploy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
